{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2918f6b5",
   "metadata": {},
   "source": [
    "# Example: Detection of Similar Queries Using Similarity-based Detector\n",
    "\n",
    "This notebook demonstrates how to use the similarity-based detector from the monitoring toolkit to identify repeated or highly similar queries.\n",
    "\n",
    "We simulate a practical scenario where an attacker sends slightly modified images to probe the model's decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36371998",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "We start by importing necessary libraries and loading the detector from the toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.registry import get_detector\n",
    "from utils.query import Query\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff96d0",
   "metadata": {},
   "source": [
    "## 2. Load Example Image\n",
    "For this demo, we use the classic dog image from ``torchvision.datasets.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d48f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg\"\n",
    "response = requests.get(URL)\n",
    "image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e01bd",
   "metadata": {},
   "source": [
    "## 3. Simulate Slightly Perturbed Image\n",
    "We simulate adversarial behaviour by adding low-amplitude Gaussian noise to the original image.\n",
    "\n",
    "The noise is imperceptible to humans but can fool a model like an adversarial example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "img_tensor = transform(image)\n",
    "\n",
    "noise_std = 0.01  \n",
    "noise = torch.randn_like(img_tensor) * noise_std\n",
    "img_noised = img_tensor + noise\n",
    "img_noised = torch.clamp(img_noised, 0, 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b4285c",
   "metadata": {},
   "source": [
    "## 4. Visualize Original vs Perturbed Image\n",
    "\n",
    "Below are original and perturbed images, along with the difference (noise) between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2bb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = torch.abs(img_noised - img_tensor)\n",
    "diff_vis = diff / diff.max()\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axs[0].imshow(img_tensor.permute(1, 2, 0))\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "axs[1].imshow(img_noised.permute(1, 2, 0))\n",
    "axs[1].set_title(\"Noised\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "axs[2].imshow(diff.permute(1, 2, 0))\n",
    "axs[2].set_title(\"Visualized Noise (absolute difference)\")\n",
    "axs[2].axis(\"off\")\n",
    "\n",
    "axs[3].imshow(diff_vis.permute(1, 2, 0))\n",
    "axs[3].set_title(\"Visualized Noise (amplified)\")\n",
    "axs[3].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac1dd0",
   "metadata": {},
   "source": [
    "## 5. Initialize Similarity-based Detector\n",
    "We use ``ImageSimilarityDetector`` to identify queries that have similarity score with any of the last 9 images greater than 0.9.\n",
    "\n",
    "The default similarity metric for an image similarity detector is the **cosine similarity** between image **embeddings**, obtained from the penultimate layer of ResNet18 pre-trained on ImageNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64412c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = get_detector(\n",
    "    \"image_similarity\", \n",
    "    config={\"threshold\": 0.9, \"max_history_size\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5b15d",
   "metadata": {},
   "source": [
    "## 6. Run Detector\n",
    "We now feed both images to the similarity detector and track its detection result after each query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136204a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    Query(input_data=img_tensor),\n",
    "    Query(input_data=img_noised)\n",
    "]\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    result = detector.process(query)\n",
    "    print(f\"Query {i}: suspicious={result.is_suspicious}, confidence={result.confidence:.4f}, reason={result.reason}\")\n",
    "    if result.is_suspicious:\n",
    "        pprint(detector.get_state(include_embedding=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7ada4",
   "metadata": {},
   "source": [
    "## Results and Interpretation\n",
    "After the second query is processed, the similarity score between the two images is 0.9978, which demonstrates that the images are nearly identical. \n",
    "\n",
    "As the similarity score is greater than 0.9, the second query is classified as suspicious. \n",
    "\n",
    "The detector with high confidence detects imperceptable modifications. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-monitoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
